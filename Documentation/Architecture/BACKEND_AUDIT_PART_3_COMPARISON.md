# BACKEND ARCHITECTURE AUDIT - Part 3: Visual Comparison & Drift Prevention

**Repository:** factsway-backend  
**Purpose:** Create side-by-side comparisons, visual diagrams, and progress tracking matrices  
**Input:** Parts 1 (Current) + 2 (Target)  
**Output:** Mermaid diagrams, comparison tables, implementation progress tracker

---

## Part 3A: Side-by-Side Architecture Comparison

### Output File: `/tmp/backend-architecture-comparison.md`

```bash
#!/bin/bash

OUTPUT="/tmp/backend-architecture-comparison.md"

cat > "$OUTPUT" << 'HEADER'
# Architecture Comparison: Current vs Target

**Purpose:** Visual comparison to prevent drift during implementation

---

## Directory Structure Comparison

### Current Structure (Before)

```
factsway-backend/
‚îú‚îÄ‚îÄ src/                              # üü¢ Electron app (stays)
‚îÇ   ‚îú‚îÄ‚îÄ main/                         # üü¢ Main process
‚îÇ   ‚îú‚îÄ‚îÄ api/                          # üü° API routes (update calls)
‚îÇ   ‚îî‚îÄ‚îÄ services/                     # üü¢ Storage services
‚îú‚îÄ‚îÄ factsway-ingestion/               # üî¥ OLD pipeline (refactor)
‚îÇ   ‚îú‚îÄ‚îÄ ingestion_engine/
‚îÇ   ‚îî‚îÄ‚îÄ app.py                        # üî¥ DELETE
‚îú‚îÄ‚îÄ migrations/                       # üü¢ Database (keep)
‚îú‚îÄ‚îÄ vault/                            # üü¢ Documents (keep)
‚îî‚îÄ‚îÄ package.json
```

### Target Structure (After)

```
factsway-platform/                    # üîµ NEW monorepo
‚îú‚îÄ‚îÄ services/                         # üîµ NEW microservices
‚îÇ   ‚îú‚îÄ‚îÄ records-service/              # üîµ NEW
‚îÇ   ‚îú‚îÄ‚îÄ ingestion-service/            # üîµ NEW (from old pipeline)
‚îÇ   ‚îú‚îÄ‚îÄ export-service/               # üîµ NEW
‚îÇ   ‚îú‚îÄ‚îÄ caseblock-service/            # üîµ NEW
‚îÇ   ‚îú‚îÄ‚îÄ signature-service/            # üîµ NEW
‚îÇ   ‚îú‚îÄ‚îÄ facts-service/                # üîµ NEW
‚îÇ   ‚îú‚îÄ‚îÄ exhibits-service/             # üîµ NEW
‚îÇ   ‚îî‚îÄ‚îÄ caselaw-service/              # üîµ NEW
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îî‚îÄ‚îÄ desktop/                      # üü° MOVED from src/
‚îÇ       ‚îú‚îÄ‚îÄ src/main/                 # üü¢ Electron (keep)
‚îÇ       ‚îú‚îÄ‚îÄ src/api/                  # üü° Routes (update)
‚îÇ       ‚îú‚îÄ‚îÄ migrations/               # üü¢ Database (keep)
‚îÇ       ‚îî‚îÄ‚îÄ vault/                    # üü¢ Documents (keep)
‚îú‚îÄ‚îÄ packages/                         # üîµ NEW shared code
‚îÇ   ‚îú‚îÄ‚îÄ shared-types/
‚îÇ   ‚îî‚îÄ‚îÄ shared-utils/
‚îî‚îÄ‚îÄ infrastructure/                   # üîµ NEW deployment configs
```

---

## Component Count Comparison

HEADER

echo "| Category | Current | Target | Change |" >> "$OUTPUT"
echo "|----------|---------|--------|--------|" >> "$OUTPUT"

cat >> "$OUTPUT" << 'COUNTS'
| TypeScript Services | 0 | 1 (records) | +1 NEW |
| Python Services | 1 (monolith) | 7 (microservices) | +6 NEW |
| Electron Components | 3 (main, preload, handlers) | 4 (+ orchestrator) | +1 NEW |
| API Route Files | ~8 | ~8 | SAME (updated calls) |
| Database Schemas | 1 (SQLite) | 1 (SQLite) | SAME |
| Deployment Targets | 1 (Desktop only) | 4 (Desktop, Web, Mobile, Enterprise) | +3 NEW |
COUNTS

cat >> "$OUTPUT" << 'FOOTER'

---

## Critical Changes Summary

### üü¢ STAYS UNCHANGED (Core Backend)

**Electron App:**
- ‚úÖ `src/main/index.ts` - Main process entry (moves to apps/desktop)
- ‚úÖ `src/main/preload.ts` - IPC bridge (moves to apps/desktop)
- ‚úÖ `src/main/handlers/` - All IPC handlers (moves to apps/desktop)
- ‚úÖ Database schema in `migrations/`
- ‚úÖ Document storage in `vault/`
- ‚úÖ Storage services (`src/main/services/`)

**Database:**
- ‚úÖ SQLite for desktop deployment
- ‚úÖ All existing migrations
- ‚úÖ Schema remains compatible

**UI Integration:**
- ‚úÖ All IPC channels stay the same
- ‚úÖ No breaking changes to frontend adapter

---

### üî¥ REMOVED (Old Ingestion)

**Python Monolith:**
- ‚ùå `factsway-ingestion/app.py` - FastAPI server (DELETE)
- ‚ùå Direct Python API calls from Electron (REPLACE with service calls)
- ‚ùå Monolithic pipeline (REFACTOR into ingestion-service)

**Reason:** Old pipeline becomes `ingestion-service`, but ingestion logic is preserved and improved.

---

### üîµ ADDED (New Components)

**Microservices (8 total):**
1. ‚ú® `services/records-service/` - TypeScript/Node, port 3001
2. ‚ú® `services/ingestion-service/` - Python/FastAPI, port 3002
3. ‚ú® `services/export-service/` - Python/FastAPI, port 3003
4. ‚ú® `services/caseblock-service/` - Python/FastAPI, port 3004
5. ‚ú® `services/signature-service/` - Python/FastAPI, port 3005
6. ‚ú® `services/facts-service/` - Python/FastAPI, port 3006
7. ‚ú® `services/exhibits-service/` - Python/FastAPI, port 3007
8. ‚ú® `services/caselaw-service/` - Python/FastAPI, port 3008

**Desktop Orchestrator:**
- ‚ú® `apps/desktop/src/main/orchestrator.ts` - Spawns/manages services as child processes
- ‚ú® PID tracking, health checks, auto-restart
- ‚ú® Service discovery via environment variables

**Shared Packages:**
- ‚ú® `packages/shared-types/` - Common TypeScript types
- ‚ú® `packages/shared-utils/` - Shared utilities

**Infrastructure:**
- ‚ú® `infrastructure/kubernetes/` - Cloud deployment configs
- ‚ú® `infrastructure/docker-compose.yml` - Local testing

---

### üü° MODIFIED (Updated)

**API Routes:**
- üîß Update to call microservices instead of direct DB/Python
- üîß Example: `POST /api/cases/:id/filing/export` now calls `export-service:3003`
- üîß Service URLs injected via environment variables

**Package.json:**
- üîß Becomes workspace root (lerna/npm workspaces)
- üîß Scripts updated for monorepo
- üîß Dependencies moved to service-specific package.json files

FOOTER

echo "" >> "$OUTPUT"
echo "Comparison complete: $OUTPUT"
```

---

## Part 3B: Mermaid Architecture Diagrams

### Output File: `/tmp/backend-architecture-diagrams.md`

```bash
#!/bin/bash

OUTPUT="/tmp/backend-architecture-diagrams.md"

cat > "$OUTPUT" << 'HEADER'
# Backend Architecture Diagrams

**Purpose:** Visual representations of current vs target architecture

---

## Current Architecture (Before)

```mermaid
graph TB
    subgraph "Electron App"
        UI[UI - React/Vue]
        IPC[IPC Bridge]
        Main[Main Process]
        API[Express API]
        DB[(SQLite Database)]
    end
    
    subgraph "Python Pipeline"
        PyAPI[FastAPI Server]
        Pipeline[Ingestion Pipeline]
        LXML[LXML Parser]
        NLP[NLP Services]
    end
    
    UI -->|invokeChannel| IPC
    IPC --> Main
    Main --> API
    API --> DB
    Main -->|HTTP| PyAPI
    PyAPI --> Pipeline
    Pipeline --> LXML
    Pipeline --> NLP
    
    style PyAPI fill:#f9f,stroke:#333,stroke-width:2px
    style Pipeline fill:#f9f,stroke:#333,stroke-width:2px
```

**Problems:**
- ‚ùå Python as separate HTTP service (overhead)
- ‚ùå Monolithic pipeline (can't scale parts independently)
- ‚ùå No service isolation
- ‚ùå Single deployment model only

---

## Target Architecture (After - Desktop)

```mermaid
graph TB
    subgraph "Electron Shell"
        UI[UI - React/Vue]
        IPC[IPC Bridge]
        Orch[Desktop Orchestrator]
        API[Express API Routes]
        DB[(SQLite)]
    end
    
    subgraph "Child Process Services"
        Records[records-service<br/>:3001]
        Ingest[ingestion-service<br/>:3002]
        Export[export-service<br/>:3003]
        CaseB[caseblock-service<br/>:3004]
        Sig[signature-service<br/>:3005]
        Facts[facts-service<br/>:3006]
        Exhibits[exhibits-service<br/>:3007]
        Caselaw[caselaw-service<br/>:3008]
    end
    
    UI -->|IPC| IPC
    IPC --> API
    Orch -->|spawn| Records
    Orch -->|spawn| Ingest
    Orch -->|spawn| Export
    Orch -->|spawn| CaseB
    Orch -->|spawn| Sig
    Orch -->|spawn| Facts
    Orch -->|spawn| Exhibits
    Orch -->|spawn| Caselaw
    
    API -->|http://localhost:3001| Records
    API -->|http://localhost:3002| Ingest
    API -->|http://localhost:3003| Export
    
    Records --> DB
    
    Orch -.PID tracking.-> Records
    Orch -.health checks.-> Ingest
    Orch -.auto-restart.-> Export
    
    style Orch fill:#90EE90,stroke:#333,stroke-width:3px
    style Records fill:#87CEEB,stroke:#333,stroke-width:2px
    style Ingest fill:#87CEEB,stroke:#333,stroke-width:2px
    style Export fill:#87CEEB,stroke:#333,stroke-width:2px
```

**Benefits:**
- ‚úÖ Services as child processes (no Docker on desktop)
- ‚úÖ Independent scaling in cloud
- ‚úÖ PID management prevents zombies
- ‚úÖ Health checks + auto-restart
- ‚úÖ Service discovery via environment variables

---

## Target Architecture (After - Cloud)

```mermaid
graph TB
    subgraph "Kubernetes Cluster"
        Ingress[Ingress/Load Balancer]
        
        subgraph "Services (Pods)"
            Records[records-service<br/>:3001]
            Ingest[ingestion-service<br/>:3002]
            Export[export-service<br/>:3003]
            CaseB[caseblock-service<br/>:3004]
            Sig[signature-service<br/>:3005]
            Facts[facts-service<br/>:3006]
            Exhibits[exhibits-service<br/>:3007]
            Caselaw[caselaw-service<br/>:3008]
        end
        
        DB[(PostgreSQL)]
        Redis[(Redis Cache)]
    end
    
    User[Web User] -->|HTTPS| Ingress
    Ingress --> Records
    Ingress --> Ingest
    Ingress --> Export
    
    Records --> DB
    Facts --> DB
    
    Records -.service mesh.-> Facts
    Ingest -.service mesh.-> Caselaw
    
    style Ingress fill:#FFD700,stroke:#333,stroke-width:3px
    style Records fill:#87CEEB,stroke:#333,stroke-width:2px
    style Ingest fill:#87CEEB,stroke:#333,stroke-width:2px
```

**Key Differences from Desktop:**
- üîß Docker containers instead of child processes
- üîß Kubernetes DNS instead of localhost
- üîß PostgreSQL instead of SQLite
- üîß Horizontal scaling (multiple replicas)
- üîß Load balancing

**Same Service Code:**
- ‚úÖ Services use environment variables for discovery
- ‚úÖ `RECORDS_SERVICE_URL=http://records-service:3001` (cloud)
- ‚úÖ `RECORDS_SERVICE_URL=http://localhost:3001` (desktop)

---

## Service Communication Flow

```mermaid
sequenceDiagram
    participant UI as UI (Frontend)
    participant API as API Routes
    participant Records as Records Service
    participant Ingest as Ingestion Service
    participant Export as Export Service
    participant DB as Database
    
    UI->>API: POST /api/cases/123/import (DOCX file)
    API->>Ingest: POST http://localhost:3002/api/ingest
    Ingest->>Ingest: Parse DOCX ‚Üí LegalDocument
    Ingest-->>API: {parsed: LegalDocument}
    API->>Records: POST http://localhost:3001/api/drafts
    Records->>DB: INSERT INTO drafts
    DB-->>Records: draft_id
    Records-->>API: {id: draft_id}
    API-->>UI: {draftId: draft_id}
    
    Note over UI,DB: Later: Export
    
    UI->>API: POST /api/cases/123/filing/export
    API->>Records: GET http://localhost:3001/api/drafts/456
    Records->>DB: SELECT FROM drafts WHERE id=456
    DB-->>Records: LegalDocument JSON
    Records-->>API: {legalDocument}
    API->>Export: POST http://localhost:3003/api/export
    Export->>Export: LegalDocument ‚Üí DOCX
    Export-->>API: {buffer: base64}
    API-->>UI: Download DOCX
```

**Environment Variable Injection:**
```typescript
// API Routes read these (set by orchestrator):
const RECORDS_URL = process.env.RECORDS_SERVICE_URL;  // http://localhost:3001
const INGEST_URL = process.env.INGESTION_SERVICE_URL; // http://localhost:3002
const EXPORT_URL = process.env.EXPORT_SERVICE_URL;    // http://localhost:3003
```

HEADER

echo "" >> "$OUTPUT"
echo "Diagrams complete: $OUTPUT"
```

---

## Part 3C: Implementation Progress Tracker

### Output File: `/tmp/backend-implementation-tracker.md`

```bash
#!/bin/bash

OUTPUT="/tmp/backend-implementation-tracker.md"

cat > "$OUTPUT" << 'HEADER'
# Implementation Progress Tracker

**Purpose:** Track completion of Runbook 0 implementation

---

## Runbook Implementation Status

HEADER

echo "| Runbook | Component | Status | Blocker | Verification |" >> "$OUTPUT"
echo "|---------|-----------|--------|---------|--------------|" >> "$OUTPUT"

cat >> "$OUTPUT" << 'TRACKER'
| RB-01 | Reference Document | ‚è≥ NOT STARTED | None | Document created |
| RB-02 | Database Schema | ‚è≥ NOT STARTED | RB-01 | Migrations run |
| RB-03 | Records Service | ‚è≥ NOT STARTED | RB-02 | Service starts on :3001 |
| RB-04 | Ingestion Service | ‚è≥ NOT STARTED | RB-02 | Service starts on :3002 |
| RB-05 | Export Service | ‚è≥ NOT STARTED | RB-04 | Service starts on :3003 |
| RB-06 | Specialized Services | ‚è≥ NOT STARTED | RB-04 | All 4 services start |
| RB-07 | Desktop Orchestrator | ‚è≥ NOT STARTED | RB-03 | Spawns all services |
| RB-08 | Frontend UI | ‚è≥ NOT STARTED | RB-07 | Import/export work |
| RB-09 | Service Discovery | ‚è≥ NOT STARTED | RB-07 | Env vars injected |
| RB-10 | Desktop Packaging | ‚è≥ NOT STARTED | RB-09 | Installer builds |
| RB-11 | Web Trial | ‚è≥ NOT STARTED | RB-05 | Web app deploys |
| RB-12 | Mobile Integration | ‚è≥ NOT STARTED | RB-11 | Mobile app connects |
| RB-13 | Enterprise Deployment | ‚è≥ NOT STARTED | RB-10 | K8s deploys |
| RB-14 | Evidence System | ‚è≥ NOT STARTED | RB-06 | Facts service works |
| RB-15 | Integration Testing | ‚è≥ NOT STARTED | RB-14 | All tests pass |
TRACKER

cat >> "$OUTPUT" << 'FOOTER'

**Legend:**
- ‚è≥ NOT STARTED - Not yet begun
- üöß IN PROGRESS - Currently working on
- ‚úÖ COMPLETE - Verified and working
- ‚ùå BLOCKED - Cannot proceed

---

## Service Creation Checklist

### Records Service (Runbook 3)

- [ ] Directory created: `services/records-service/`
- [ ] package.json with dependencies
- [ ] src/server.ts (Express app)
- [ ] src/routes/templates.ts
- [ ] src/routes/cases.ts
- [ ] src/routes/drafts.ts
- [ ] src/repositories/sqlite/
- [ ] tests/ with integration tests
- [ ] Dockerfile for cloud deployment
- [ ] build.js for desktop bundling (pkg)
- [ ] Service starts on port 3001 ‚úì
- [ ] Health endpoint responds ‚úì
- [ ] CRUD operations work ‚úì

### Ingestion Service (Runbook 4)

- [ ] Directory created: `services/ingestion-service/`
- [ ] requirements.txt with dependencies
- [ ] app/main.py (FastAPI app)
- [ ] app/routes/ingest.py
- [ ] app/parsers/ (LXML logic from old pipeline)
- [ ] app/models/legal_document.py
- [ ] tests/ with pytest
- [ ] Dockerfile for cloud deployment
- [ ] build.spec for desktop bundling (PyInstaller)
- [ ] Service starts on port 3002 ‚úì
- [ ] /api/ingest endpoint works ‚úì
- [ ] LegalDocument JSON output matches schema ‚úì

### Export Service (Runbook 5)

- [ ] Directory created: `services/export-service/`
- [ ] requirements.txt with dependencies
- [ ] app/main.py (FastAPI app)
- [ ] app/routes/export.py
- [ ] app/renderers/docx_renderer.py
- [ ] app/renderers/pdf_renderer.py
- [ ] tests/ with pytest
- [ ] Dockerfile for cloud deployment
- [ ] build.spec for desktop bundling
- [ ] Service starts on port 3003 ‚úì
- [ ] /api/export endpoint works ‚úì
- [ ] DOCX preserves formatting ‚úì
- [ ] PDF generation works ‚úì

### Desktop Orchestrator (Runbook 7)

- [ ] File created: `apps/desktop/src/main/orchestrator.ts`
- [ ] DesktopOrchestrator class implemented
- [ ] startAllServices() method
- [ ] stopAllServices() method
- [ ] healthCheck() method
- [ ] cleanupZombies() method
- [ ] PID tracking (service-pids.json)
- [ ] Environment variable injection
- [ ] Auto-restart on crash
- [ ] Integration with main process
- [ ] All 8 services spawn successfully ‚úì
- [ ] Health checks run every 30s ‚úì
- [ ] Graceful shutdown on app quit ‚úì

---

## Critical Path Items

**Must complete in order:**

1. ‚úÖ **Runbook 0** - Specification complete (DONE)
2. ‚è≥ **Runbook 1** - Reference document
3. ‚è≥ **Runbook 2** - Database schema
4. ‚è≥ **Runbook 3** - Records service (FIRST service)
5. ‚è≥ **Runbook 4** - Ingestion service (FIRST Python service)
6. ‚è≥ **Runbook 7** - Desktop orchestrator (CRITICAL)
7. ‚è≥ **Runbook 5** - Export service
8. ‚è≥ **Runbook 6** - Specialized services (4 services)
9. ‚è≥ **Runbook 8** - Frontend UI integration
10. ‚è≥ **Runbook 9** - Service discovery config
11. ‚è≥ **Runbook 10** - Desktop packaging

**Parallel tracks after RB-07:**
- Web/Mobile (RB-11, RB-12)
- Enterprise (RB-13)
- Evidence (RB-14)
- Testing (RB-15)

---

## Drift Prevention Checklist

**Before starting each runbook:**

- [ ] Re-read Runbook 0 relevant sections
- [ ] Check this architecture map for current state
- [ ] Verify no duplicate functionality exists
- [ ] Confirm IPC channels won't break
- [ ] Test service discovery works
- [ ] Run integration tests after changes

**During implementation:**

- [ ] Follow Runbook 0 specifications exactly
- [ ] No improvisation or "improvements"
- [ ] Document any deviations in journal
- [ ] Update this tracker after each task

**After completing runbook:**

- [ ] Update status in this tracker
- [ ] Verify all checklist items
- [ ] Run full test suite
- [ ] Commit with runbook reference
- [ ] Update architecture diagrams if needed

FOOTER

echo "" >> "$OUTPUT"
echo "Progress tracker complete: $OUTPUT"
```

---

## Part 3D: Drift Detection Script

### Output File: `/tmp/backend-drift-detector.sh`

```bash
#!/bin/bash

cat > /tmp/backend-drift-detector.sh << 'SCRIPT'
#!/bin/bash
# Drift Detection Script
# Run this periodically during implementation to catch architectural drift

cd /path/to/factsway-backend

echo "=== DRIFT DETECTION REPORT ==="
echo "Generated: $(date)"
echo ""

# Check 1: No duplicate ingestion code
echo "## Check 1: Duplicate Ingestion Detection"
echo ""

if [ -d "factsway-ingestion" ] && [ -d "services/ingestion-service" ]; then
  echo "‚ö†Ô∏è WARNING: Both old and new ingestion exist!"
  echo "   Old: factsway-ingestion/"
  echo "   New: services/ingestion-service/"
  echo "   Action: Verify migration complete, delete old"
else
  echo "‚úÖ PASS: No duplicate ingestion code"
fi
echo ""

# Check 2: Services use environment variables (not hardcoded URLs)
echo "## Check 2: Service Discovery Pattern"
echo ""

hardcoded=$(grep -r "http://localhost:[0-9]" services --include="*.ts" --include="*.py" | grep -v "process.env" | wc -l | tr -d ' ')

if [ "$hardcoded" -gt 0 ]; then
  echo "‚ùå FAIL: Found $hardcoded hardcoded localhost URLs"
  grep -rn "http://localhost:[0-9]" services --include="*.ts" --include="*.py" | grep -v "process.env" | head -5
  echo "   Action: Replace with process.env.SERVICE_NAME_URL"
else
  echo "‚úÖ PASS: All service URLs use environment variables"
fi
echo ""

# Check 3: No direct database access from API routes
echo "## Check 3: API Routes Use Services (Not Direct DB)"
echo ""

direct_db=$(grep -r "db\.\|database\." src/api/routes --include="*.ts" | grep -v "// " | wc -l | tr -d ' ')

if [ "$direct_db" -gt 3 ]; then
  echo "‚ö†Ô∏è WARNING: Found $direct_db potential direct DB accesses in API routes"
  echo "   Expected: API routes call services, services access DB"
  echo "   Action: Verify these are service calls, not direct DB"
else
  echo "‚úÖ PASS: API routes appear to use services"
fi
echo ""

# Check 4: Desktop orchestrator exists if services exist
echo "## Check 4: Orchestrator Implementation Status"
echo ""

if [ -d "services" ]; then
  service_count=$(find services -maxdepth 1 -type d | wc -l | tr -d ' ')
  
  if [ ! -f "apps/desktop/src/main/orchestrator.ts" ] && [ ! -f "src/main/orchestrator.ts" ]; then
    echo "‚ùå FAIL: Services exist but no orchestrator found!"
    echo "   Services: $service_count"
    echo "   Action: Create DesktopOrchestrator (Runbook 7)"
  else
    echo "‚úÖ PASS: Orchestrator exists"
  fi
else
  echo "‚úÖ PASS: No services yet, orchestrator not needed"
fi
echo ""

# Check 5: IPC channels not broken
echo "## Check 5: IPC Channel Integrity"
echo ""

registered=$(grep -r "ipcMain.handle" src/main --include="*.ts" | wc -l | tr -d ' ')
invoked=$(grep -r "invokeChannel" src --include="*.ts" --include="*.tsx" | wc -l | tr -d ' ')

echo "   Registered handlers: $registered"
echo "   Invocations: $invoked"

if [ "$invoked" -gt "$registered" ]; then
  echo "‚ö†Ô∏è WARNING: More invocations than handlers (possible missing handlers)"
else
  echo "‚úÖ PASS: Channel invocations <= registered handlers"
fi
echo ""

# Check 6: Monorepo structure (if supposed to be created)
echo "## Check 6: Monorepo Structure Check"
echo ""

if [ -f "lerna.json" ] || [ -f "pnpm-workspace.yaml" ]; then
  if [ ! -d "services" ]; then
    echo "‚ö†Ô∏è WARNING: Monorepo config exists but no services/ directory"
  elif [ ! -d "apps" ]; then
    echo "‚ö†Ô∏è WARNING: Monorepo config exists but no apps/ directory"
  else
    echo "‚úÖ PASS: Monorepo structure looks correct"
  fi
else
  echo "‚ÑπÔ∏è INFO: Not yet using monorepo structure"
fi
echo ""

echo "=== END DRIFT DETECTION ==="
echo ""
echo "Run this script periodically during implementation to catch drift early"

SCRIPT

chmod +x /tmp/backend-drift-detector.sh

echo "Drift detector created: /tmp/backend-drift-detector.sh"
```

---

## Execution Instructions

**Run Part 3 after Parts 1 & 2:**

```bash
# Part 3A: Side-by-side comparison
bash /path/to/part-3a-comparison.sh

# Part 3B: Mermaid diagrams
bash /path/to/part-3b-diagrams.sh

# Part 3C: Progress tracker
bash /path/to/part-3c-tracker.sh

# Part 3D: Drift detector (run periodically)
bash /tmp/backend-drift-detector.sh

# Combine outputs
cat /tmp/backend-architecture-comparison.md \
    /tmp/backend-architecture-diagrams.md \
    /tmp/backend-implementation-tracker.md \
    > /tmp/BACKEND_COMPARISON_AND_TRACKING.md

echo "‚úÖ Comparison and tracking complete!"
echo "üìÑ Output: /tmp/BACKEND_COMPARISON_AND_TRACKING.md"
```

---

## Expected Outputs

After Part 3, you will have:

1. **Side-by-side comparison** - Current vs Target directory structures
2. **Component count matrix** - What's added/removed/modified
3. **Mermaid diagrams** - Visual architecture (current, desktop target, cloud target)
4. **Service communication flow** - Sequence diagram
5. **Implementation tracker** - Progress checklist for all 15 runbooks
6. **Service creation checklists** - Task lists for each service
7. **Drift detection script** - Automated checks to run during implementation

**File size estimate:** ~800-1200 lines

**Usage:** Reference these during implementation to stay aligned with Runbook 0

---

## How to Use During Implementation

**Before starting any runbook:**
1. Review relevant sections in comparison document
2. Check current state in architecture map
3. Verify no duplicate functionality

**During implementation:**
1. Follow Runbook 0 specifications exactly
2. Run drift detector after major changes
3. Update progress tracker

**After completing runbook:**
1. Verify all checklist items complete
2. Run drift detector (should pass)
3. Update tracker status
4. Commit with runbook reference

---

## Notes

- These are VISUAL GUIDES, not executable code
- Use Mermaid diagrams in documentation
- Update tracker as you progress
- Run drift detector frequently
- Keep comparison doc open during implementation
